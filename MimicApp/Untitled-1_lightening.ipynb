{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# import custom libraries\n",
    "import sys\n",
    "sys.path.append(\"C:\\\\DATA\\\\Tasks\\\\lib\\\\hk\")\n",
    "import hk_psql\n",
    "\n",
    "import plotly.express as px  # (version 4.7.0 or higher)\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "ADD_DATA = \"C:\\\\DATA\\\\data\\\\raw\\\\physionet_challenge_2019\\\\\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2',\n",
       "       'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN',\n",
       "       'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
       "       'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium',\n",
       "       'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
       "       'Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2',\n",
       "       'HospAdmTime', 'ICULOS', 'SepsisLabel', 'id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(ADD_DATA+'df_AA.csv')\n",
    "df_valid = pd.read_csv(ADD_DATA+'df_BB.csv')\n",
    "\n",
    "\n",
    "#df_train['prev_sepsis'] = df_train['SepsisLabel'].shift(periods=7).bfill()\n",
    "#df_valid['prev_sepsis'] = df_valid['SepsisLabel'].shift(periods=7).bfill()\n",
    "df_train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract missingness pattern\n",
    "cols_ts = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp',\n",
    "       'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN',\n",
    "       'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
    "       'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium',\n",
    "       'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
    "       'Fibrinogen', 'Platelets']\n",
    "\n",
    "\n",
    "a = ((df_train[cols_ts].isnull().sum() / len(df_train) * 100)>80)\n",
    "cols_irreg = a[a==True].index.tolist()\n",
    "\n",
    "cols_patt = [col+'_pattern' for col in cols_irreg]\n",
    "cols_count = [col+'_count' for col in cols_irreg]\n",
    "\n",
    "for col in cols_irreg:\n",
    "    df_train[col+'_pattern'] = df_train[col].notnull().astype(int)\n",
    "    df_valid[col+'_pattern'] = df_valid[col].notnull().astype(int)\n",
    "    \n",
    "    a = df_train.groupby('id')[col+'_pattern'].rolling(min_periods=1, window=6).sum().reset_index(drop=True)\n",
    "    df_train[col+'_count'] = a\n",
    "\n",
    "    a = df_valid.groupby('id')[col+'_pattern'].rolling(min_periods=1, window=6).sum().reset_index(drop=True)\n",
    "    df_valid[col+'_count'] = a\n",
    "\n",
    "df_train['all_counts'] = df_train[cols_count].sum(axis=1)\n",
    "df_valid['all_counts'] = df_valid[cols_count].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_train.groupby('id')['Lactate'+'_pattern'].rolling(min_periods=1, window=6).sum().reset_index(drop=True)\n",
    "df = pd.DataFrame()\n",
    "df['Lactate'] = df_train['Lactate']\n",
    "df['id'] = df_train['id']\n",
    "df['c'] = df_train.groupby('id')['Lactate'+'_pattern'].rolling(min_periods=1, window=6).sum().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR                  0\n",
      "O2Sat               0\n",
      "Temp                0\n",
      "SBP                 0\n",
      "MAP                 0\n",
      "DBP                 0\n",
      "Resp                0\n",
      "BaseExcess          0\n",
      "HCO3                0\n",
      "FiO2                0\n",
      "pH                  0\n",
      "PaCO2               0\n",
      "SaO2                0\n",
      "AST                 0\n",
      "BUN                 0\n",
      "Alkalinephos        0\n",
      "Calcium             0\n",
      "Chloride            0\n",
      "Creatinine          0\n",
      "Bilirubin_direct    0\n",
      "Glucose             0\n",
      "Lactate             0\n",
      "Magnesium           0\n",
      "Phosphate           0\n",
      "Potassium           0\n",
      "Bilirubin_total     0\n",
      "TroponinI           0\n",
      "Hct                 0\n",
      "Hgb                 0\n",
      "PTT                 0\n",
      "WBC                 0\n",
      "Fibrinogen          0\n",
      "Platelets           0\n",
      "HospAdmTime         0\n",
      "ICULOS              0\n",
      "Age                 0\n",
      "dtype: int64\n",
      "HR                  0\n",
      "O2Sat               0\n",
      "Temp                0\n",
      "SBP                 0\n",
      "MAP                 0\n",
      "DBP                 0\n",
      "Resp                0\n",
      "BaseExcess          0\n",
      "HCO3                0\n",
      "FiO2                0\n",
      "pH                  0\n",
      "PaCO2               0\n",
      "SaO2                0\n",
      "AST                 0\n",
      "BUN                 0\n",
      "Alkalinephos        0\n",
      "Calcium             0\n",
      "Chloride            0\n",
      "Creatinine          0\n",
      "Bilirubin_direct    0\n",
      "Glucose             0\n",
      "Lactate             0\n",
      "Magnesium           0\n",
      "Phosphate           0\n",
      "Potassium           0\n",
      "Bilirubin_total     0\n",
      "TroponinI           0\n",
      "Hct                 0\n",
      "Hgb                 0\n",
      "PTT                 0\n",
      "WBC                 0\n",
      "Fibrinogen          0\n",
      "Platelets           0\n",
      "HospAdmTime         0\n",
      "ICULOS              0\n",
      "Age                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# a link for imputation tutorial\n",
    "# https://towardsdatascience.com/how-to-fill-missing-data-with-pandas-8cb875362a0d\n",
    "\n",
    "cols = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp',\n",
    "       'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN',\n",
    "       'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
    "       'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium',\n",
    "       'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
    "       'Fibrinogen', 'Platelets','HospAdmTime','ICULOS','Age']\n",
    "\n",
    "\n",
    "df_train[cols] = df_train.groupby('id')[cols].ffill().bfill()\n",
    "df_train[cols] = df_train[cols].fillna( df_train[cols].mean() )\n",
    "df_train[cols] = df_train[cols].fillna( 0 )\n",
    "\n",
    "df_valid[cols] = df_valid.groupby('id')[cols].ffill().bfill()\n",
    "df_valid[cols] = df_valid[cols].fillna( df_valid[cols].mean() )\n",
    "df_valid[cols] = df_valid[cols].fillna( 0 )\n",
    "\n",
    "mean_train = df_train[cols].mean().tolist()\n",
    "std_train = df_train[cols].std().tolist()\n",
    "\n",
    "#print(df_train.isnull().sum())\n",
    "#print(df_train[cols].mean(), df_train[cols].std())\n",
    "\n",
    "df_train[cols]=(df_train[cols]-df_train[cols].mean())/df_train[cols].std()\n",
    "df_valid[cols]=(df_valid[cols]-df_train[cols].mean())/df_train[cols].std()\n",
    "\n",
    "#print(df_train[cols].mean(), df_train[cols].std())\n",
    "\n",
    "\n",
    "print(df_train[cols].isnull().sum())\n",
    "print(df_train[cols].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in cols:\n",
    "    df_train[col] = pd.qcut(df_train[col], 3, labels=['L','N','H'])\n",
    "    df_train[col] = df_train[col].cat.codes\n",
    "    df_valid[col] = pd.qcut(df_valid[col], 3, labels=['L','N','H'])\n",
    "    df_valid[col] = df_valid[col].cat.codes\n",
    "\n",
    "\n",
    "#print(df_train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_cols = [*cols, *cols_patt, *cols_count]\n",
    "all_cols = [*cols, *cols_count,'all_counts']\n",
    "all_cols = [*cols, *cols_patt, *cols_count,'all_counts','ICULOS','HospAdmTime'] # , 'prev_sepsis'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 91)\n"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "# read csv and put data in a list of tensors (each patient)\n",
    "\n",
    "\n",
    "train_data={'X':[], 'y':[]}\n",
    "for id in df_train['id'].unique():\n",
    "    #train_data['X'].append(df_train[df_train['id']==id][[*cols, 'prev_sepsis']].values)\n",
    "    train_data['X'].append(df_train[df_train['id']==id][[*all_cols]].values)\n",
    "    train_data['y'].append(df_train[df_train['id']==id]['SepsisLabel'].values)\n",
    "\n",
    "print( train_data['X'][0].shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 91)\n"
     ]
    }
   ],
   "source": [
    "# valid data\n",
    "# read csv and put data in a list of tensors (each patient)\n",
    "\n",
    "\n",
    "valid_data={'X':[], 'y':[]}\n",
    "for id in df_valid['id'].unique():\n",
    "    #valid_data['X'].append(df_valid[df_valid['id']==id][[*cols, 'prev_sepsis']].values)\n",
    "    valid_data['X'].append(df_valid[df_valid['id']==id][[*all_cols]].values)\n",
    "    valid_data['y'].append(df_valid[df_valid['id']==id]['SepsisLabel'].values)\n",
    "\n",
    "print( valid_data['X'][0].shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 91) (54,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data['X'][0].shape, train_data['y'][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device='cpu'\n",
    "print(device)\n",
    "\n",
    "DEBUG=False\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "num_epochs = 10\n",
    "data_dir = 'TB_with_tune'\n",
    "num_samples=10\n",
    "\n",
    "\n",
    "\n",
    "params = {\n",
    "    'input_size':train_data['X'][0].shape[-1],\n",
    "    'num_classes':2,\n",
    "    'num_epochs':20,\n",
    "    'bidirectional':False\n",
    "\n",
    "}\n",
    "\n",
    "{'lr': 0.005857717666242615, 'BS': 500, 'hidden_size': 10, 'hidden_size2': 7, 'do1': 0.2738131929177843, 'do2': 0.23638112638259945}\n",
    "{'lr': 0.005857717666242615, 'BS': 500, 'hidden_size': 10, 'hidden_size2': 7, 'do1': 0.2738131929177843, 'do2': 0.23638112638259945}\n",
    "{'lr': 0.001345745549601815, 'BS': 200, 'hidden_size': 13, 'hidden_size2': 10, 'do1': 0.7246378339446564, 'do2': 0.6352657731209103}\n",
    "{'lr': 0.0013676728932238839, 'BS': 500, 'hidden_size': 13, 'hidden_size2': 4, 'do1': 0.4449960661200688, 'do2': 0.887982434157199}\n",
    "{'lr': 0.002483836566033312, 'BS': 200, 'hidden_size': 9, 'hidden_size2': 7, 'do1': 0.6479722393440036, 'do2': 0.7842471069565781}\n",
    "\n",
    "hparams = {}\n",
    "hparams['lr'] = 0.002483836566033312\n",
    "hparams['batch_size'] = 200\n",
    "hparams['hidden_size'] = 9\n",
    "hparams['hidden_size2'] = 7\n",
    "hparams['do1'] = 0.6479722393440036\n",
    "hparams['do2'] = 0.7842471069565781\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_backbone(trial):\n",
    "    # https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html\n",
    "\n",
    "    hparams = {}\n",
    "    hparams['lr'] = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
    "    #hparams['lr'] = 0.00188\n",
    "    hparams['batch_size'] = trial.suggest_categorical('BS', [200,500,1000])\n",
    "    #hparams['batch_size'] = 200\n",
    "    hparams['hidden_size'] = trial.suggest_int('hidden_size',7,15)\n",
    "    hparams['hidden_size2'] = trial.suggest_int('hidden_size2',3,12)\n",
    "    hparams['do1'] = trial.suggest_uniform('do1',0,1)\n",
    "    hparams['do2'] = trial.suggest_uniform('do2',0,1)\n",
    "\n",
    "    #hparams['hidden_size'] = \n",
    "    #hparams['hidden_size'] = [8, 5]\n",
    "    #hparams['dropout'] = [0.8, 0.8]\n",
    "    #hparams['D'] = len(hparams['hidden_size'])\n",
    "\n",
    "    \n",
    "\n",
    "    return hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    }
   ],
   "source": [
    "# create a DataLoader object\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.Normalize(mean_train, std_train)])\n",
    "\n",
    "class MinimalDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "\n",
    "        self.X = list(map(lambda a: torch.tensor(a).float(), X))\n",
    "        self.y = list(map(lambda a: torch.tensor(a).long(), y))\n",
    "\n",
    "        #print(type(self.X[0]))\n",
    "        #print(self.transform(self.X[0].transpose))\n",
    "        if self.transform is not None:\n",
    "            self.X = list(map(lambda a: self.transform(a), self.X))\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        \n",
    "        \n",
    "\n",
    "        sample = {\"X\": X, \"y\": y}\n",
    "\n",
    "        return X, y\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # for padding\n",
    "    # https://suzyahyah.github.io/pytorch/2019/07/01/DataLoader-Pad-Pack-Sequence.html\n",
    "    #X = [i[0] for i in batch]\n",
    "    #y = [i[1] for i in batch]\n",
    "\n",
    "    (xx, yy) = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    y_lens = [len(y) for y in yy]\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
    "    yy_pad = pad_sequence(yy, batch_first=True, padding_value=0)\n",
    "\n",
    "    return xx_pad, yy_pad, x_lens, y_lens\n",
    "\n",
    "train_dataset = MinimalDataset(train_data['X'], train_data['y'], transform=None)\n",
    "train_loader = DataLoader(train_dataset, batch_size=hparams['batch_size'], shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "valid_dataset = MinimalDataset(valid_data['X'], valid_data['y'], transform=None)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=hparams['batch_size'], shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000\n"
     ]
    }
   ],
   "source": [
    "(X_pad, y_pad, X_lens, y_lens) = next(iter(valid_loader))\n",
    "\n",
    "print(len(train_loader.sampler), len(valid_loader.sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n",
    "def cal_auc_batch (y_true, y_pred, y_lens):\n",
    "    y_pred = torch.unbind(y_pred, dim=0) # a list of bs tensors [n_class, L]\n",
    "    #print((y_pred[0].shape))\n",
    "    \n",
    "    y_pred = [x[:,:i] for i,x in zip(y_lens, y_pred)]\n",
    "    #print((y_pred[0].shape), y_pred[1].shape)\n",
    "\n",
    "    y_pred = torch.cat(y_pred,dim=1) # dim [n_class, sum(lens)]\n",
    "    y_pred = torch.amax(y_pred, 0).detach().cpu().numpy()\n",
    "    #print((y_pred.shape))\n",
    "    \n",
    "    ### y_true\n",
    "    y_true = torch.unbind(y_true, dim=0) # a list of bs binary values [L]\n",
    "    #print((y_true[0].shape))\n",
    "    \n",
    "    y_true = [x[:i] for i,x in zip(y_lens, y_true)]\n",
    "    #print((y_true[0].shape), y_true[1].shape)\n",
    "\n",
    "    y_true = torch.cat(y_true,dim=0).detach().cpu().numpy()\n",
    "        # dim [n_class, sum(lens)]\n",
    "    #print((y_true.shape))\n",
    "    auc_score = metrics.roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    return y_pred, y_true, auc_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class myLSTM_lit(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    input_size - will be 1 in this example since we have only 1 predictor (a sequence of previous values)\n",
    "    hidden_size - Can be chosen to dictate how much hidden \"long term memory\" the network will have\n",
    "    output_size - This will be equal to the prediciton_periods input to get_x_y_pairs\n",
    "    \"\"\"\n",
    "    def __init__(self, hparams, params):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.input_size = params['input_size']\n",
    "        self.num_classes = params['num_classes']\n",
    "        self.bidirectional = params['bidirectional']\n",
    "        self.D = 2 if self.bidirectional else 1\n",
    "\n",
    "        self.hidden_size = hparams['hidden_size']\n",
    "        self.hidden_size2 = hparams['hidden_size2']\n",
    "        self.do1 = hparams['do1']\n",
    "        self.do2 = hparams['do2']\n",
    "        self.batch_size = hparams[\"batch_size\"]\n",
    "        self.lr = hparams['lr']\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size = self.input_size, hidden_size =  self.hidden_size, batch_first=True,\n",
    "                                dropout=self.do1, bidirectional =self.bidirectional)        \n",
    "        \n",
    "        self.lstm2 = nn.LSTM(input_size = self.hidden_size, hidden_size =  self.hidden_size2, batch_first=True,\n",
    "                                dropout=self.do1, bidirectional =self.bidirectional)        \n",
    "        \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(self.D*self.hidden_size)\n",
    "        self.bn2 = nn.BatchNorm1d(self.D*self.hidden_size2)\n",
    "        #self.batch_normalisation2 = nn.BatchNorm1d(self.num_classes)\n",
    "\n",
    "        \n",
    "        self.linear = nn.Linear(self.D*self.hidden_size2, self.num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.init_states()\n",
    "    \n",
    "    def forward(self, x, x_lens):\n",
    "        \n",
    "        # initialize the hidden state.\n",
    "        \"\"\"\n",
    "        x: (batch, seq_len, input_size)\n",
    "\n",
    "        out: (batch, seq_len, hidden_size)\n",
    "        h_n, c_n: (num_layers * num_directions, batch, hidden_size)\n",
    "        \"\"\"\n",
    "        #x = x.to(device)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        if DEBUG: print('input.shape = ',x.shape, x.get_device())\n",
    "        if DEBUG: print('states[0].shape = ', states[0].shape, states[0].get_device())\n",
    "\n",
    "        # if variable length: do padding\n",
    "\n",
    "        x_padded_packed = pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "\n",
    "        # LSTM1\n",
    "        states = (self.h_n, self.c_n)\n",
    "        x_padded_packed, (self.h_n, self.c_n) = self.lstm1(x_padded_packed, states)\n",
    "        self.h_n = self.h_n.detach()\n",
    "        self.c_n = self.c_n.detach()\n",
    "        output_padded, output_lengths = pad_packed_sequence(x_padded_packed, batch_first=True)\n",
    "\n",
    "        \n",
    "        # BN1\n",
    "        output_padded = output_padded.view(self.batch_size, self.D*self.hidden_size,-1)        \n",
    "        output_padded = self.bn1(output_padded)\n",
    "        output_padded = output_padded.view(self.batch_size, -1, self.D*self.hidden_size)\n",
    "        x_padded_packed = pack_padded_sequence(output_padded, x_lens, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        # LSTM 2\n",
    "        states2 = (self.h_n2, self.c_n2)\n",
    "        x_padded_packed, (self.h_n2, self.c_n2) = self.lstm2(x_padded_packed, states2)\n",
    "        self.h_n2 = self.h_n2.detach()\n",
    "        self.c_n2 = self.c_n2.detach()\n",
    "        output_padded, output_lengths = pad_packed_sequence(x_padded_packed, batch_first=True)\n",
    "\n",
    "        # BN 2\n",
    "        output_padded = output_padded.view(self.batch_size, self.D*self.hidden_size2,-1)        \n",
    "        output_padded = self.bn2(output_padded)\n",
    "        output_padded = output_padded.view(self.batch_size, -1, self.D*self.hidden_size2)\n",
    "\n",
    "        \n",
    "        # FC layer\n",
    "        out = self.linear(output_padded)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print('lstm_out.shape = ',output_padded.shape)\n",
    "        if DEBUG: print('output_lengths',output_lengths)\n",
    "        if DEBUG: print('lstm_out.shape = ',output_padded.shape)\n",
    "        #if DEBUG: print('lstm_out.view(len(x), -1).shape = ',lstm_out.view(len(x), -1).shape)\n",
    "\n",
    "        # if variable length: unpadd\n",
    "        #lstm_out = pad_packed_sequence(lstm_out, batch_first=True)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        #print(out.shape)\n",
    "        #out = out.view(self.batch_size, self.num_classes,-1)\n",
    "        #print(out.shape)\n",
    "\n",
    "        #out = self.batch_normalisation2(out)\n",
    "        #out = out.view(self.batch_size, -1, self.num_classes)\n",
    "        \n",
    "        if DEBUG: print('fc_out.shape = ',out.shape)\n",
    "        \n",
    "        #out = nn.Sigmoid()(output_padded)\n",
    "        #predictions = nn.functional.log_softmax(out)\n",
    "        #predictions = torch.swapaxes(predictions, 1, 2)\n",
    "        #predictions = predictions.transpose(1,2)\n",
    "        return out\n",
    "\n",
    "    def init_states(self):\n",
    "        '''\n",
    "        Initiate hidden states.\n",
    "        '''\n",
    "        # Shape for hidden state and cell state: num_layers * num_directions, batch, hidden_size\n",
    "        \n",
    "        #h_0 = torch.randn(1, self.batch_size, self.hidden_dim)\n",
    "        #c_0 = torch.randn(1, self.batch_size, self.hidden_dim)\n",
    "\n",
    "        # The Variable API is now semi-deprecated, so we use nn.Parameter instead.\n",
    "        # Note: For Variable API requires_grad=False by default;\n",
    "        # For Parameter API requires_grad=True by default.\n",
    "        \n",
    "        #h_0 = nn.Parameter(h_0, requires_grad=True)\n",
    "        #c_0 = nn.Parameter(c_0, requires_grad=True)\n",
    "\n",
    "        \"\"\"initialize the hidden and cell states\"\"\"\n",
    "        self.h_n = torch.zeros(self.D, self.batch_size, self.hidden_size).float().to(device)\n",
    "        self.c_n = torch.zeros(self.D, self.batch_size, self.hidden_size).float().to(device)\n",
    "\n",
    "        self.h_n2 = torch.zeros(self.D, self.batch_size, self.hidden_size2).float().to(device)\n",
    "        self.c_n2 = torch.zeros(self.D, self.batch_size, self.hidden_size2).float().to(device)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr= self.lr)\n",
    "        #lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "        return [optimizer]#, [lr_scheduler]  \n",
    "  \n",
    "  \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        X_pad, y_pad, X_lens, y_lens = batch\n",
    "        \n",
    "        #model.init_states()\n",
    "        \n",
    "        X_padded = X_pad.to(device)\n",
    "        y_padded = y_pad.to(device)\n",
    "\n",
    "        if DEBUG: print('X_padded.shape = ', X_padded.shape)\n",
    "        if DEBUG: print('y_padded.shape = ', y_padded.shape)\n",
    "        if DEBUG: print('len(lens) = ', (X_lens))\n",
    "        \n",
    "        if DEBUG: print('device ', X_padded.get_device())\n",
    "        # Forward pass\n",
    "        y_pred = self(X_padded, x_lens=X_lens)\n",
    "        y_pred = torch.swapaxes(y_pred, 1, 2)\n",
    "        loss = criterion(y_pred, y_padded)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        y_pred, y_true, auc_score = cal_auc_batch (y_padded, y_pred, y_lens)\n",
    "        return {'loss': loss, 'train_loss_batch': loss.detach(), 'train_auc_batch': auc_score}\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        X_pad, y_pad, X_lens, y_lens = batch\n",
    "        \n",
    "        #model.init_states()\n",
    "        \n",
    "        X_padded = X_pad\n",
    "        y_padded = y_pad\n",
    "\n",
    "        if DEBUG: print('X_padded.shape = ', X_padded.shape)\n",
    "        if DEBUG: print('y_padded.shape = ', y_padded.shape)\n",
    "        if DEBUG: print('len(lens) = ', (X_lens))\n",
    "        \n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred = self(X_padded, x_lens=X_lens)\n",
    "        y_pred = torch.swapaxes(y_pred, 1, 2)\n",
    "        loss = criterion(y_pred, y_padded)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        y_pred, y_true, auc_score = cal_auc_batch (y_padded, y_pred, y_lens)\n",
    "        \n",
    "        return {'val_loss_batch': loss, 'val_auc_batch': auc_score}\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        X_pad, y_pad, X_lens, y_lens = batch\n",
    "        \n",
    "        #model.init_states()\n",
    "        \n",
    "        X_padded = X_pad\n",
    "        y_padded = y_pad\n",
    "\n",
    "        if DEBUG: print('X_padded.shape = ', X_padded.shape)\n",
    "        if DEBUG: print('y_padded.shape = ', y_padded.shape)\n",
    "        if DEBUG: print('len(lens) = ', (X_lens))\n",
    "        \n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred = self(X_padded, x_lens=X_lens)\n",
    "        y_pred = torch.swapaxes(y_pred, 1, 2)\n",
    "\n",
    "        y_pred, y_true, auc_score = cal_auc_batch (y_padded, y_pred, y_lens)\n",
    "\n",
    "        return y_pred, y_true, auc_score\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['train_loss_batch'] for x in outputs]).mean()\n",
    "        avg_auc = np.stack([x['train_auc_batch'] for x in outputs]).mean()\n",
    "        self.log(\"train_loss_epoch\", avg_loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        self.log(\"train_auc_epoch\", avg_auc, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "\n",
    "        #return {'train_loss_epoch': avg_loss, 'train_auc_epoch': avg_auc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss_batch'] for x in outputs]).mean()\n",
    "        avg_auc = np.stack([x['val_auc_batch'] for x in outputs]).mean()\n",
    "        self.log(\"val_loss_epoch\", avg_loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        self.log(\"val_auc_epoch\", avg_auc, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "\n",
    "        return {'val_loss_epoch': avg_loss, 'val_auc_epoch': avg_auc}\n",
    "   \n",
    "    def train_dataloader(self):\n",
    "        \n",
    "        train_dataset = MinimalDataset(train_data['X'], train_data['y'])\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, \n",
    "                                    num_workers = 0,\n",
    "                                    drop_last=False,\n",
    "                                    shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \n",
    "        valid_dataset = MinimalDataset(valid_data['X'], valid_data['y'])\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=self.batch_size, \n",
    "                                    num_workers = 0,\n",
    "                                    drop_last=False,\n",
    "                                    shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "        return valid_loader\n",
    "\n",
    "\n",
    "# https://pytorch-lightning.readthedocs.io/en/latest/extensions/callbacks.html\n",
    "# https://pytorch-lightning.readthedocs.io/en/0.7.1/hooks.html\n",
    "\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "class MyCallbacks2(Callback):\n",
    "    \n",
    "    def on_train_start(self,  trainer, pl_module):\n",
    "        print(\"################################\")\n",
    "    def backward(self):\n",
    "        self.backward(retain_graph=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 258, 89])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17564\\2511730729.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_pad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_pad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_lens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_hierarchical\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# https://pypi.org/project/pytorch-model-summary/\n",
    "\n",
    "\n",
    "from pytorch_model_summary import summary\n",
    "\n",
    "model = myLSTM_lit(hparams, params)\n",
    "# model.init_states()\n",
    "\n",
    "(X_pad, y_pad, X_lens, y_lens) = next(iter(train_loader))\n",
    "\n",
    "print(X_pad.shape)\n",
    "\n",
    "print(summary(model, X_pad.to(device), X_lens.to(device), show_input=False, show_hierarchical=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################                                      \n",
      "Epoch 49: 100%|██████████| 10/10 [00:00<00:00, 20.60it/s, loss=0.00141, v_num=173, train_loss_step=0.00141, val_loss_step=0.00791, val_loss_epoch=0.00618, val_auc_epoch=0.703, train_loss_epoch=0.00132, train_auc_epoch=0.809]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*dropout after all but last recurrent layer*\")\n",
    "\n",
    "logger = pl.loggers.TensorBoardLogger('TB_optuna', name='run1')\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=50, fast_dev_run=False,\n",
    "                    gpus=1, accelerator=\"gpu\",\n",
    "                    log_every_n_steps=5,\n",
    "                    logger=logger,\n",
    "                    callbacks = [MyCallbacks2()],\n",
    "                    enable_model_summary=False\n",
    "                    )\n",
    "model = myLSTM_lit(hparams, params)\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Optuna\n",
    "https://github.com/optuna/optuna-examples/blob/main/pytorch/pytorch_lightning_simple.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch-lightning.readthedocs.io/en/latest/extensions/callbacks.html\n",
    "# https://pytorch-lightning.readthedocs.io/en/0.7.1/hooks.html\n",
    "\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*The reported value is ignored because this `step` 0 is*\")\n",
    "class MyCallbacks3(Callback):\n",
    "    \n",
    "    def on_train_start(self,  trainer, pl_module):\n",
    "        #print(\"#################hh###############\")\n",
    "        return\n",
    "    #def backward(self, use_amp, loss, optimizer):\n",
    "        #print(\"HHHHHHHHHHHHHHHHHHHHHHHH\")\n",
    "        #self.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    \n",
    "    #early_stop = pl.callbacks.EarlyStopping('call_loss', patience=4)\n",
    "    \n",
    "    #model = Model(inp_C_bbone=inp_C, out_C_bbone=out_C, backbone=backbone)\n",
    "    hparams = create_backbone(trial)\n",
    "    \n",
    "    model = myLSTM_lit(hparams, params)\n",
    "     \n",
    "    trainer = Trainer(logger=False, \n",
    "                      enable_checkpointing=False,\n",
    "                      gpus=1,\n",
    "                      accelerator='gpu',\n",
    "                      max_epochs=50, \n",
    "                      #deterministic=True,\n",
    "                      callbacks = [PyTorchLightningPruningCallback(trial, monitor=\"val_auc_epoch\"),\n",
    "                                MyCallbacks3()],\n",
    "                    #progress_bar_refresh_rate=0,\n",
    "                    enable_model_summary=False\n",
    "                    )\n",
    "                      \n",
    "    trainer.fit(model)\n",
    "    \n",
    "    #score = trainer.predict(model,valid_loader)\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    print(trainer.callback_metrics[\"val_auc_epoch\"].item())\n",
    "    a=1\n",
    "    return trainer.callback_metrics[\"val_auc_epoch\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:27:41,008]\u001b[0m A new study created in memory with name: no-name-b9dd03f0-2d56-4488-88dd-77338d7105ee\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 10/10 [00:00<00:00, 21.15it/s, loss=0.0204, train_loss_step=0.0212, val_loss_step=0.0176, val_loss_epoch=0.0179, val_auc_epoch=0.589, train_loss_epoch=0.0199, train_auc_epoch=0.573]\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:28:05,929]\u001b[0m Trial 0 finished with value: 0.5889094322733742 and parameters: {'lr': 0.00038844542013174906, 'BS': 200, 'hidden_size': 14, 'hidden_size2': 9, 'do1': 0.6375208960436358, 'do2': 0.575602893753034}. Best is trial 0 with value: 0.5889094322733742.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5889094322733742\n",
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00, 10.24it/s, loss=0.3, train_loss_step=0.276, val_loss_step=0.321, val_loss_epoch=0.311, val_auc_epoch=0.566, train_loss_epoch=0.273, train_auc_epoch=0.524]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:28:24,090]\u001b[0m Trial 1 finished with value: 0.5659354498014131 and parameters: {'lr': 0.00011970873248557104, 'BS': 500, 'hidden_size': 14, 'hidden_size2': 11, 'do1': 0.05119366562045369, 'do2': 0.6524186154656548}. Best is trial 0 with value: 0.5889094322733742.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "0.5659354498014131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 10/10 [00:00<00:00, 21.23it/s, loss=0.0152, train_loss_step=0.016, val_loss_step=0.0164, val_loss_epoch=0.0148, val_auc_epoch=0.721, train_loss_epoch=0.0145, train_auc_epoch=0.684] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:28:48,932]\u001b[0m Trial 2 finished with value: 0.7205353905014714 and parameters: {'lr': 0.0012691201434260108, 'BS': 200, 'hidden_size': 9, 'hidden_size2': 8, 'do1': 0.3960474360470265, 'do2': 0.7887007096788996}. Best is trial 2 with value: 0.7205353905014714.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "0.7205353905014714\n",
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00, 11.96it/s, loss=0.0787, train_loss_step=0.0782, val_loss_step=0.0694, val_loss_epoch=0.0682, val_auc_epoch=0.773, train_loss_epoch=0.071, train_auc_epoch=0.709] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:29:06,582]\u001b[0m Trial 3 finished with value: 0.7727703658527187 and parameters: {'lr': 0.0006870190359772087, 'BS': 500, 'hidden_size': 13, 'hidden_size2': 5, 'do1': 0.19877387220034304, 'do2': 0.831363922310521}. Best is trial 3 with value: 0.7727703658527187.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "0.7727703658527187\n",
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00,  9.45it/s, loss=0.0591, train_loss_step=0.0491, val_loss_step=0.0782, val_loss_epoch=0.0743, val_auc_epoch=0.623, train_loss_epoch=0.0515, train_auc_epoch=0.695]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:29:24,863]\u001b[0m Trial 4 finished with value: 0.6227448547251728 and parameters: {'lr': 0.0013676728932238839, 'BS': 500, 'hidden_size': 13, 'hidden_size2': 4, 'do1': 0.4449960661200688, 'do2': 0.887982434157199}. Best is trial 3 with value: 0.7727703658527187.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "0.6227448547251728\n",
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00,  8.98it/s, loss=0.00439, train_loss_step=0.00362, val_loss_step=0.00361, val_loss_epoch=0.00361, val_auc_epoch=0.756, train_loss_epoch=0.00365, train_auc_epoch=0.692]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:29:46,812]\u001b[0m Trial 5 finished with value: 0.7564050261553779 and parameters: {'lr': 0.0039312934246863865, 'BS': 500, 'hidden_size': 13, 'hidden_size2': 10, 'do1': 0.8877363518856369, 'do2': 0.13394566757579296}. Best is trial 3 with value: 0.7727703658527187.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "0.7564050261553779\n",
      "Epoch 49: 100%|██████████| 10/10 [00:00<00:00, 14.74it/s, loss=0.000978, train_loss_step=0.0011, val_loss_step=0.00173, val_loss_epoch=0.00133, val_auc_epoch=0.714, train_loss_epoch=0.000928, train_auc_epoch=0.749]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:30:19,679]\u001b[0m Trial 6 finished with value: 0.7144139143209761 and parameters: {'lr': 0.0035805452055892076, 'BS': 200, 'hidden_size': 10, 'hidden_size2': 7, 'do1': 0.5206350635113318, 'do2': 0.49287267416568414}. Best is trial 3 with value: 0.7727703658527187.\u001b[0m\n",
      "GPU available: True, used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "0.7144139143209761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  90%|█████████ | 9/10 [00:00<00:00, 18.12it/s, loss=1.02, train_loss_step=0.755, val_loss_step=0.849, val_loss_epoch=0.836, val_auc_epoch=0.443, train_loss_epoch=1.120, train_auc_epoch=0.428] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:30:21,220]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 10/10 [00:03<00:00,  3.08it/s, loss=1.02, train_loss_step=0.755, val_loss_step=0.849, val_loss_epoch=0.836, val_auc_epoch=0.443, train_loss_epoch=1.120, train_auc_epoch=0.428]    \n",
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00,  9.40it/s, loss=0.000219, train_loss_step=0.000196, val_loss_step=0.000341, val_loss_epoch=0.000347, val_auc_epoch=0.693, train_loss_epoch=0.000187, train_auc_epoch=0.741]\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:30:42,776]\u001b[0m Trial 8 finished with value: 0.6934188499749682 and parameters: {'lr': 0.005857717666242615, 'BS': 500, 'hidden_size': 14, 'hidden_size2': 12, 'do1': 0.2738131929177843, 'do2': 0.23638112638259945}. Best is trial 3 with value: 0.7727703658527187.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6934188499749682\n",
      "Validation sanity check: 100%|██████████| 2/2 [00:00<00:00, 19.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:30:42,958]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:30:43,223]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  9.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:30:43,510]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  9.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:30:43,780]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|█████     | 1/2 [00:00<00:00,  5.19it/s, loss=0.653, train_loss_step=0.304, val_loss_step=0.848, val_loss_epoch=0.848, val_auc_epoch=0.543, train_loss_epoch=0.394, train_auc_epoch=0.635]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:30:45,540]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 100%|██████████| 2/2 [00:00<00:00, 12.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:30:45,787]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00,  9.15it/s, loss=0.0227, train_loss_step=0.0196, val_loss_step=0.0257, val_loss_epoch=0.0225, val_auc_epoch=0.720, train_loss_epoch=0.0203, train_auc_epoch=0.718]\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:06,967]\u001b[0m Trial 15 finished with value: 0.7202892591399981 and parameters: {'lr': 0.0007764286883017848, 'BS': 500, 'hidden_size': 10, 'hidden_size2': 10, 'do1': 0.578808169026439, 'do2': 0.4609740540370547}. Best is trial 3 with value: 0.7727703658527187.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7202892591399981\n",
      "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  9.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:07,245]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2/2 [00:24<00:00, 12.22s/it, loss=0.653, train_loss_step=0.304, val_loss_step=0.848, val_loss_epoch=0.848, val_auc_epoch=0.543, train_loss_epoch=0.394, train_auc_epoch=0.635]\n",
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00,  5.11it/s, loss=0.207, train_loss_step=0.183, val_loss_step=0.241, val_loss_epoch=0.241, val_auc_epoch=0.721, train_loss_epoch=0.183, train_auc_epoch=0.659]\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:25,398]\u001b[0m Trial 17 finished with value: 0.7206643836859485 and parameters: {'lr': 0.00026639925598135694, 'BS': 1000, 'hidden_size': 13, 'hidden_size2': 7, 'do1': 0.14182209819051506, 'do2': 0.3734469945349415}. Best is trial 3 with value: 0.7727703658527187.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7206643836859485\n",
      "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  9.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:25,654]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 100%|██████████| 2/2 [00:00<00:00, 13.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:25,896]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 100%|██████████| 1/1 [00:00<00:00,  7.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:26,132]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:26,371]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:26,614]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:26,868]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:27,131]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  8.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:27,404]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|█████     | 1/2 [00:00<00:00,  4.92it/s, loss=2.7, train_loss_step=2.140, val_loss_step=0.694, val_loss_epoch=0.694, val_auc_epoch=0.583, train_loss_epoch=2.420, train_auc_epoch=0.515] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:29,588]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 100%|██████████| 2/2 [00:00<00:00, 12.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:29,850]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 4/4 [00:00<00:00, 10.64it/s, loss=1.54, train_loss_step=0.824, val_loss_step=0.823, val_loss_epoch=0.818, val_auc_epoch=0.562, train_loss_epoch=1.420, train_auc_epoch=0.633]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:31,580]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 2.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it, loss=2.7, train_loss_step=2.140, val_loss_step=0.694, val_loss_epoch=0.694, val_auc_epoch=0.583, train_loss_epoch=2.420, train_auc_epoch=0.515]2]\n",
      "Epoch 2: 100%|██████████| 4/4 [00:01<00:00,  2.03it/s, loss=1.54, train_loss_step=0.824, val_loss_step=0.823, val_loss_epoch=0.818, val_auc_epoch=0.562, train_loss_epoch=1.420, train_auc_epoch=0.633]\n",
      "Epoch 7:  50%|█████     | 1/2 [00:00<00:00,  5.57it/s, loss=0.741, train_loss_step=0.706, val_loss_step=0.628, val_loss_epoch=0.628, val_auc_epoch=0.594, train_loss_epoch=0.716, train_auc_epoch=0.480]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:34,906]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 7.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:35,109]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:35,297]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:35,491]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:35,684]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:31:35,879]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 10/10 [00:00<00:00, 15.86it/s, loss=0.00563, train_loss_step=0.0054, val_loss_step=0.0272, val_loss_epoch=0.0276, val_auc_epoch=0.734, train_loss_epoch=0.00527, train_auc_epoch=0.815] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:32:06,997]\u001b[0m Trial 35 finished with value: 0.7336237147234738 and parameters: {'lr': 0.001571773179199497, 'BS': 200, 'hidden_size': 14, 'hidden_size2': 7, 'do1': 0.17290372584629576, 'do2': 0.7078921081786125}. Best is trial 3 with value: 0.7727703658527187.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "0.7336237147234738\n",
      "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  9.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:32:07,289]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  90%|█████████ | 9/10 [00:00<00:00, 18.22it/s, loss=0.00151, train_loss_step=0.0012, val_loss_step=0.009, val_loss_epoch=0.00882, val_auc_epoch=0.684, train_loss_epoch=0.00141, train_auc_epoch=0.844]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:32:17,793]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 16.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00,  9.76it/s, loss=0.0124, train_loss_step=0.0111, val_loss_step=0.0106, val_loss_epoch=0.0104, val_auc_epoch=0.759, train_loss_epoch=0.011, train_auc_epoch=0.714] 844]\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:32:39,422]\u001b[0m Trial 38 finished with value: 0.7585965087723355 and parameters: {'lr': 0.0017146594443056423, 'BS': 500, 'hidden_size': 14, 'hidden_size2': 7, 'do1': 0.17324680170360482, 'do2': 0.7393718438960639}. Best is trial 3 with value: 0.7727703658527187.\u001b[0m\n",
      "GPU available: True, used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7585965087723355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  9.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:32:39,686]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  9.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:32:39,950]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  9.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:32:40,217]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 4/4 [00:00<00:00, 11.78it/s, loss=0.258, train_loss_step=0.201, val_loss_step=0.489, val_loss_epoch=0.489, val_auc_epoch=0.469, train_loss_epoch=0.242, train_auc_epoch=0.663]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:32:41,796]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 2.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:32:41,993]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  9.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:32:42,264]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  9.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:32:42,547]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:32:42,827]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 100%|██████████| 2/2 [00:00<00:00, 17.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:32:43,053]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  9.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:32:43,335]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  8.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-16 19:32:43,637]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "#pl.utilities.distributed.log.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=17)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=50, timeout=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "569 38917\n",
      "roc is:  0.7360357088712876\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "predictions = trainer.predict(model, valid_loader)\n",
    "\n",
    "y=[]\n",
    "scores=[]\n",
    "for (y_pred, y_true, auc_score) in predictions[:]:\n",
    "    \n",
    "    #print(y_pred.shape, y_true.shape)\n",
    "    \n",
    "    y.append(y_true)\n",
    "    scores.append(y_pred)\n",
    "\n",
    "\n",
    "y = np.concatenate(y)\n",
    "scores = np.concatenate(scores)\n",
    "\n",
    "print(sum(y==1), len(y))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=1)\n",
    "print('roc is: ', metrics.roc_auc_score(y, scores))\n",
    "\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "\n",
    "plt.plot(fpr, tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "#fpr, tpr, thresholds = roc_curve(y, scores, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(predictions))\n",
    "print(len(predictions))\n",
    "print(type(predictions[0]))\n",
    "print(len(predictions[0]))\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(train_data):\n",
    "    train_data.sort(key=lambda data: len(data), reverse=True)\n",
    "    data_length = [len(data) for data in train_data]\n",
    "    train_data =  torch.nn.utils.rnn.pad_sequence(train_data, batch_first=True, padding_value=0)\n",
    "    return train_data, data_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=2, collate_fn=collate_fn)\n",
    "\n",
    "for data, length in train_dataloader:\n",
    "    print(data)\n",
    "    print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, length in train_dataloader:\n",
    "    data = rnn_utils.pack_padded_sequence(data, length, batch_first=True)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.LSTM(1, 5, batch_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MyData(train_x)\n",
    "train_dataloader = DataLoader(train_data, batch_size=2, collate_fn=collate_fn)\n",
    "\n",
    "flag = 0\n",
    "for data, length in train_dataloader:\n",
    "    data = torch.nn.utils.rnn.pack_padded_sequence(data, length, batch_first=True)\n",
    "    output, hidden = net(data)\n",
    "    if flag == 0:\n",
    "        print(output)\n",
    "        flag = 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2f29e1a05e7eec16e11fbddc27661320510c37e25360333d406961ee2486f09"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('dashVis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
